{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Load_Dataset.ipynb","provenance":[{"file_id":"1QN63DmiSQD0cOzJn3LzFUpxBfHHg0A8n","timestamp":1613812112007}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"id":"nRtkIl2BtigO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"61CxSPpSoIjm"},"source":["##Mounting drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67qUOy8hmg1g","executionInfo":{"status":"ok","timestamp":1613935315724,"user_tz":-360,"elapsed":22259,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}},"outputId":"df901e78-d805-4615-fc6a-ce97ec5df245"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VSI9XhZioM7T"},"source":["# %cd /content/drive/My\\ Drive/Data_mining/Lab2/Notebooks\r\n","# !ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NCWoRGTXvrAy"},"source":["#Installing Packages"]},{"cell_type":"code","metadata":{"id":"xoeUSShAvtNQ"},"source":["# !pip install ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dP4QJB1JUWU"},"source":["##Importing Libraries"]},{"cell_type":"code","metadata":{"id":"wUgpW27EnTyT"},"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","import copy\r\n","import math\r\n","import csv\r\n","import time\r\n","import re\r\n","import tracemalloc\r\n","import matplotlib.pyplot as plt\r\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\r\n","# from ipynb.fs.full.Load_dataset import load_dataset, get_dataset_names\r\n","\r\n","plt.rc('xtick',labelsize=15)\r\n","plt.rc('ytick',labelsize=15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yB4FH9ebXEzW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1Q7Gv-SnOu3"},"source":["import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.datasets import load_iris, load_digits, load_wine\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Ea8-JSnnOvN"},"source":["# X and Y are dataframe\n","def dataset_to_dict(name, X_df, Y_df, categoricalX= 'off'):\n","    return {\n","        'name': name,\n","        'attributes' : X_df.fillna(X_df.mean()).to_numpy(), #X_df.fillna(X_df.mean()) fills nan values of columns with mean of that columns\n","        'target' : np.squeeze(Y_df.to_numpy()),\n","        'categoricalX' : categoricalX,\n","        'trainSize': dataset_train_test_size[name][0],\n","        'testSize': dataset_train_test_size[name][1]\n","    }\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-3xGZZWnOvR"},"source":["# X and Y are numpy array\n","def dataset_array_to_dict(name, X, Y, categoricalX= 'off'):\n","    return {\n","        'name': name,\n","        'attributes' : X,\n","        'target' : np.squeeze(Y),\n","        'categoricalX' : categoricalX,\n","        'trainSize': dataset_train_test_size[name][0],\n","        'testSize': dataset_train_test_size[name][1]\n","    }\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3FCUrqInOvV"},"source":["def load_dataset_iris():\n","  X, Y = load_iris(return_X_y= True)\n","  print('dataset: iris')\n","  # print(X)\n","  # print(Y)\n","  print('instances = {}, features= {} '.format(X.shape[0], X.shape[1]))\n","  X= X\n","  Y= np.squeeze(Y)\n","  return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysFfDT4NnOva"},"source":["\n","def load_dataset_digits():\n","    X, Y = load_digits(return_X_y= True)\n","    print('dataset: digits')\n","    # print(X)\n","    # print(Y)\n","    print('instances = {}, features= {} '.format(X.shape[0], X.shape[1]))\n","    X= X\n","    Y= np.squeeze(Y)\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lZer48wnOvf"},"source":["def load_dataset_wine():\n","    X, Y = load_wine(return_X_y= True)\n","    print('dataset: wine')\n","    # print(X)\n","    # print(Y)\n","    print('instances = {}, features= {} '.format(X.shape[0], X.shape[1]))\n","    X= X\n","    Y= np.squeeze(Y)\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXRC9IEEnOvn"},"source":["def load_dataset_australian():\n","    df = pd.read_csv ('/content/drive/My Drive/Thesis/Datasets/Australian/australian.dat', sep=r'\\s+',header=None)\n","    X_df = df.iloc[:,:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: australian')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQ0m_t8gnOvs"},"source":["def load_dataset_breastTissue():\n","    df = pd.read_excel('/content/drive/My Drive/Thesis/Datasets/BreastTissue/BreastTissue.xls', sheet_name='Data')\n","    X_df = df.iloc[:, 1:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: breastTissue')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6sP3ZBEdnOvw"},"source":["def load_dataset_dermatology():\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Dermatology/dermatology.data', sep=\",\",header=None)\n","    df = df.replace(['?'], np.nan)\n","    df = df.astype('float64')\n","    X_df = df.iloc[:,:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: dermatology')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nICUNAmcnOv4"},"source":["def load_dataset_glass():\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Glass/glass.data', sep=\",\",header=None)\n","    X_df = df.iloc[:,1:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: glass')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qh8cv4g2nOwY"},"source":["def load_dataset_parkinsons():\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Parkinsons/parkinsons.data', sep=\",\",header=None)\n","    df = df.iloc[1:, 1:] #removing first column and first row\n","    X_df = df.iloc[:,[i for i in range(len(df.columns)) if i!=16]]\n","    Y_df = df.iloc[:,16] #17th column contains label\n","    X_df = X_df.astype('float64')\n","    print('dataset: parkinsons')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LDq3_plMnOwe"},"source":["def load_dataset_pima():\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Pima/diabetes.csv', sep=\",\",header=None)\n","    X_df = df.iloc[1:,:-1]\n","    Y_df = df.iloc[1:,-1]\n","\n","    X_df = X_df.astype('float64')\n","\n","    print('dataset: pima')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aG1NLnSQnOwj"},"source":["def load_dataset_sonar():\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Sonar/sonar.all-data', sep=\",\",header=None)\n","    X_df = df.iloc[:,:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: sonar')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SqfA4HqnOwn"},"source":["def load_dataset_yeast():\n","    # here '\\s+' is regular expression for any number of whitespace\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Yeast/yeast.data', sep= r'\\s+',header=None)\n","    X_df = df.iloc[:,1:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: yeast')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yMDtNfAunOwu"},"source":["def load_dataset_heart():\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Heart/heart.dat', sep= \" \",header=None)\n","    X_df = df.iloc[:,:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: heart')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G1InzjOonOw1"},"source":["def load_dataset_segmentation():\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Segmentation/segment.dat', sep= r'\\s+',header=None)\n","    X_df = df.iloc[:,:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: segmentation')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ei-RvJH3nOw5"},"source":["def load_dataset_ionosphere():\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Ionosphere/ionosphere.data', sep= \",\",header=None)\n","    X_df = df.iloc[:,:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: ionosphere')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"St8Mrrz6tg0v"},"source":["def load_dataset_ecoli():\n","    # here '\\s+' is regular expression for any number of whitespace\n","    df = pd.read_csv('/content/drive/My Drive/Thesis/Datasets/Ecoli/ecoli.data', sep= r'\\s+',header=None)\n","    # print(df)\n","    X_df = df.iloc[:,1:-1]\n","    Y_df = df.iloc[:,-1]\n","    print('dataset: ecoli')\n","    print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","    X= X_df.fillna(X_df.mean()).to_numpy()\n","    Y= np.squeeze(Y_df.to_numpy())\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"feDme2BEnOxA"},"source":["def load_dataset_sampleDataset1():\n","  # here '\\s+' is regular expression for any number of whitespace\n","  df = pd.read_csv('/content/drive/My Drive/Data_mining/Lab2/Datasets/sampleDataset1.csv', sep= ',',header=None)\n","  # print(df)\n","  X_df = df.iloc[:,:-1]\n","  Y_df = df.iloc[:,-1]\n","  print('dataset: sampleDataset1')\n","\n","  print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","  X= X_df.fillna(X_df.mean()).to_numpy()\n","  Y= np.squeeze(Y_df.to_numpy())\n","  return X, Y\n","# load_dataset_sampleDataset1()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRkHRPHKmkpr"},"source":["def load_dataset_sampleDataset2():\n","  # here '\\s+' is regular expression for any number of whitespace\n","  df = pd.read_csv('/content/drive/My Drive/Data_mining/Lab2/Datasets/sampleDataset2.csv', sep= ',',header=None)\n","  # print(df)\n","  X_df = df.iloc[:,:-1]\n","  Y_df = df.iloc[:,-1]\n","  print('dataset: sampleDataset2')\n","\n","  print('instances = {}, features= {} '.format(X_df.shape[0], X_df.shape[1]))\n","  X= X_df.fillna(X_df.mean()).to_numpy()\n","  Y= np.squeeze(Y_df.to_numpy())\n","  return X, Y\n","# load_dataset_sampleDataset2()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fP7-HoEKng_9"},"source":["## Dataset loading\n","load_dataset(dataset) function takes a parameter dataset = name of dataset to load.\n","<br>\n","returns a dictionary like, <br>\n","\n","```\n","{\n","        'name': dataset name,\n","        'attributes' : X,\n","        'target' : Y,\n","        'categoricalX' : 'on'/'off'\n","}\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"70_cYNSFrFi8"},"source":["dataset_dict={\n","  'iris' : load_dataset_iris,\n","  'digits' : load_dataset_digits,\n","  'wine' : load_dataset_wine,\n","  'australian' : load_dataset_australian,\n","  'breastTissue' : load_dataset_breastTissue,\n","  'dermatology' : load_dataset_dermatology,\n","  'glass' : load_dataset_glass,\n","  'parkinsons' : load_dataset_parkinsons,\n","  'pima' : load_dataset_pima,\n","  'sonar' : load_dataset_sonar,\n","  'yeast' : load_dataset_yeast,\n","  'heart' : load_dataset_heart,\n","  'segmentation' : load_dataset_segmentation,\n","  'ionosphere' : load_dataset_ionosphere,\n","  'ecoli' : load_dataset_ecoli,\n","  'sampleDataset1' : load_dataset_sampleDataset1,\n","  'sampleDataset2' : load_dataset_sampleDataset2,\n","  }\n","\n","def get_dataset_names():\n","   dataset_names = np.array([key for key, value in dataset_dict.items()])\n","   return dataset_names\n","   \n","def load_dataset(dataset):\n","  return dataset_dict[dataset]()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kxZbyi_fCatk","executionInfo":{"status":"ok","timestamp":1613935649090,"user_tz":-360,"elapsed":993,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}},"outputId":"9f186893-b813-47b0-eaa1-1faab6544796"},"source":["# datasetNames = get_dataset_names()\r\n","# print(datasetNames)\r\n","# for datasetName in datasetNames:\r\n","#   X, Y= load_dataset(datasetName)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['iris' 'digits' 'wine' 'australian' 'breastTissue' 'dermatology' 'glass'\n"," 'parkinsons' 'pima' 'sonar' 'yeast' 'heart' 'segmentation' 'ionosphere'\n"," 'ecoli' 'sampleDataset1' 'sampleDataset2']\n","dataset: iris\n","instances = 150, features= 4 \n","dataset: digits\n","instances = 1797, features= 64 \n","dataset: wine\n","instances = 178, features= 13 \n","dataset: australian\n","instances = 690, features= 14 \n","dataset: breastTissue\n","instances = 106, features= 9 \n","dataset: dermatology\n","instances = 366, features= 34 \n","dataset: glass\n","instances = 214, features= 9 \n","dataset: parkinsons\n","instances = 195, features= 22 \n","dataset: pima\n","instances = 768, features= 8 \n","dataset: sonar\n","instances = 208, features= 60 \n","dataset: yeast\n","instances = 1484, features= 8 \n","dataset: heart\n","instances = 270, features= 13 \n","dataset: segmentation\n","instances = 2310, features= 19 \n","dataset: ionosphere\n","instances = 351, features= 34 \n","dataset: ecoli\n","instances = 336, features= 7 \n","dataset: sampleDataset1\n","instances = 14, features= 4 \n","dataset: sampleDataset2\n","instances = 14, features= 4 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GCuH7mGrCqys"},"source":[""],"execution_count":null,"outputs":[]}]}